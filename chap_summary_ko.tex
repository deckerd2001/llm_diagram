% ==========================================================
% 9. 요약과 실용적인 정리
% ==========================================================
\section{요약과 실용적인 정리}

이 장에서는 앞선 장들에서 다룬 핵심 아이디어를 정리하고,
트랜스포머 학습이 실제 하드웨어에서 어떻게 수행되는지에 대한
실용적인 질문들과 연결한다.
새로운 표기법을 도입하기보다는,
실행 다이어그램을 읽거나 연산 비용을 추정하거나
모델 병렬화 방식을 결정할 때 유용한
몇 가지 사고 모형(mental model)에 초점을 맞춘다.

\subsection{기울기에서 그래프, 그리고 트랜스포머로}

이 문서의 앞부분에서는 세 가지 층위의 직관을 쌓아 왔다.

\begin{itemize}
  \item \textbf{선형 변환으로서의 기울기.}
        한 레이어를 통과하는 역전파는,
        또 다른 계산 그래프로 볼 수 있다.
        여기서 각 순전파 연산은 하나 이상의 역전파 연산
        (보통 전치된 matmul 등)을 기여한다.
        이 관점은 다음과 같은 간단한 경험 법칙으로 이어진다:
        \emph{선형 레이어 하나는 역전파에서
        대략 순전파의 두 배 비용을 유발한다.}
  \item \textbf{그래프 표기 규칙.}
        순전파 텐서, 기울기, 파라미터는
        명시적인 차원(shape) 라벨을 가진 노드로 표현된다.
        화살표와 라벨을 통해, 코드를 보지 않고도
        각 단계에서 어떤 matmul과 원소별 연산이 일어나는지
        읽어낼 수 있다.
  \item \textbf{단일 노드 트랜스포머.}
        하나의 트랜스포머 레이어는 다음 구성 요소들의 합성일 뿐이다.
        \begin{itemize}
          \item 임베딩 lookup + 위치 인코딩,
          \item MHA (레이어 정규화, Q/K/V 프로젝션,
                어텐션, 출력 프로젝션, 잔차 연결),
          \item MLP (레이어 정규화, 상향 프로젝션,
                비선형 활성 함수, 하향 프로젝션, 잔차 연결),
          \item 출력 프로젝션 + 소프트맥스 + 손실.
        \end{itemize}
        각 블록에는 순전파 그래프가 있고,
        이에 정확히 대응하는 역전파 그래프가 존재하는데,
        순전파의 각 matmul마다 역전파에서
        한두 개의 matmul이 짝을 이룬다.
\end{itemize}

Section~\ref{sec:sn}의 단일 노드 다이어그램은
이후에 등장하는 모든 병렬 변형의 “기본 케이스(base case)”다.
어떤 병렬 실행 구성도, 결국은
이 동일한 기반 계산 그래프를 쪼개고(split), 복제하고(replicate),
다시 이어 붙이는(reconnect) 방법이라고 볼 수 있다.

\subsection{연산량과 메모리: 무엇이 중요한가}

모든 레이어를 관통해 나타나는 공통적인 패턴들은 다음과 같다.

\begin{itemize}
  \item \textbf{matmul이 지배적이다.}
        대부분의 FLOPs는 선형 레이어에 들어 있다
        (Q/K/V 프로젝션, 어텐션 출력 프로젝션,
        MLP 상향/하향 프로젝션, 최종 출력 프로젝션).
        elementwise 연산(softmax, GELU, layernorm 등)은
        정확도와 안정성에는 중요하지만,
        연산량 측면에서는 상대적으로 저렴하다.
  \item \textbf{matmul의 역전파 비용은 대략 순전파의 두 배.}
        순전파의 matmul $XW$ 하나는 최소한 다음 두 개를 만든다.
        \begin{itemize}
          \item 입력 $X$로 기울기를 전파하기 위한 역전파 matmul 하나,
          \item 가중치 $W$에 기울기를 누적하기 위한 역전파 matmul 하나.
        \end{itemize}
        이는 MHA와 MLP에 대한 역전파 다이어그램에서
        명시적으로 확인할 수 있다.
  \item \textbf{어텐션과 MLP가 주된 비용원.}
        다중 헤드 어텐션의 Q/K/V 프로젝션과
        출력 프로젝션, 그리고 MLP의 상향/하향 프로젝션이
        대부분의 FLOPs를 차지한다.
        레이어 정규화와 잔차 연결, 활성 함수 등은
        상대적으로 저렴하다.
  \item \textbf{잔차 연결은 비용을 크게 늘리지 않는다.}
        잔차는 기울기 경로를 분기시키긴 하지만,
        점근적인 복잡도를 바꾸지는 않는다.
        잔차 add는 순전파·역전파 모두에서
        가벼운 elementwise 연산만 추가한다.
  \item \textbf{레이어 정규화는 항상 있지만, 비용은 상대적으로 작다.}
        레이어 정규화는 토큰당 약간의 연산과
        소량의 파라미터를 추가한다.
        역전파는 ReLU 같은 단순 활성 함수보다 조금 복잡하지만,
        여전히 주변의 큰 matmul들에 비하면 훨씬 저렴하다.
\end{itemize}

따라서 모델의 비용을 대략적으로 추정할 때는,
큰 matmul들의 개수만 세고,
해당 층들에 대해서는 역전파가
순전파의 약 두 배 비용이 든다고 기억하는 것만으로도
충분한 경우가 많다.

\subsection{단일 노드, TP, DP, DP+TP 비교}

뒤쪽 장들에서는 네 가지 실행 모드를 비교했다.

\begin{itemize}
  \item \textbf{단일 노드 (Section~\ref{sec:sn}).}
        모든 파라미터와 활성값이 하나의 디바이스에 존재한다.
        이 장의 다이어그램은 참조 구현에 해당한다:
        샤딩도 없고 집합 통신도 없으며,
        단지 matmul과 elementwise 연산이 차례대로 수행될 뿐이다.
  \item \textbf{텐서 병렬화 (Section~\ref{sec:tp}).}
        가중치 행렬과 일부 활성값을
        \emph{모델 샤드(model shard)} 내부의 $N_T$개 디바이스에 나누어 저장한다.
        컬럼 병렬/로우 병렬 선형 레이어가
        단일 노드의 matmul을 대체한다.
        부분 결과를 합치거나(shard 합산),
        샤딩된 텐서를 다시 조립하기 위해,
        레이어 그래프 \emph{내부에} All-Reduce와 All-Gather가 등장한다.
  \item \textbf{데이터 병렬화 (Section~\ref{sec:dp}).}
        전체 모델(또는 전체 TP 샤드)을 $N_D$ 디바이스에 복제한다.
        각 복제본은 서로 다른 미니배치 조각을 보고,
        단일 노드 또는 TP 설정에서와 동일한
        순전파/역전파 그래프를 실행한다.
        새롭게 등장하는 집합 통신은,
        역전파 마지막에 파라미터 기울기에 대해 수행하는
        All-Reduce 한 번뿐이다.
  \item \textbf{DP + TP (Section~\ref{sec:dp_tp}).}
        각 데이터 병렬 복제본 자체가 하나의 TP 그룹이다.
        TP 그룹 내부에서는 Section~\ref{sec:tp}에서 설명한
        레이어 내부 집합 통신(All-Reduce, All-Gather)이 그대로 적용된다.
        복제본들 사이에서는 각 TP 샤드에 대한 기울기를 평균 내기 위해
        추가적인 All-Reduce를 수행한다.
        일부 레이어(예: vocabulary-parallel 출력 헤드)는,
        이후 연산이 전체(샤딩되지 않은) 텐서를 필요로 할 때
        활성값에 대한 All-Gather를 요구한다.
\end{itemize}

즉, 다음과 같이 요약할 수 있다.

\begin{center}
\begin{tabular}{ll}
\textbf{Single node} & 집합 통신 없음, 전체 가중치가 한 디바이스에 존재 \\[0.2em]
\textbf{TP}          & 가중치/활성값 샤딩, 레이어 내부 집합 통신 \\[0.2em]
\textbf{DP}          & 모델 복제, 기울기 All-Reduce만 수행 \\[0.2em]
\textbf{DP+TP}       & 각 복제본 안에서 TP + 복제본 간 기울기 All-Reduce
\end{tabular}
\end{center}

개념적으로 이들 모드 중 어느 것도
트랜스포머가 \emph{무엇을} 계산하는지를 바꾸지는 않는다.
단지, 그래프의 각 조각이 어느 디바이스에서 실행되는지와
부분 결과들이 어떻게 다시 이어 붙는지가 달라질 뿐이다.

\subsection{도식 읽는 방법과 활용}

이 문서 전반의 다이어그램들은 반복적으로 마주치는
몇 가지 질문에 답하도록 설계되었다.

\begin{itemize}
  \item \textbf{큰 matmul은 어디에 있는가?}
        $[B,S,D]$와 같은 모양의 활성 텐서와,
        $[D,D_{\text{ff}}]$, $[D,D]$, $[D,D_{\text{vocab}}]$ 형태의
        가중치 행렬을 연결하는 직사각형 노드를 찾아보라.
        이들이 FLOPs의 주된 원천이다.
  \item \textbf{기울기는 어디로 흐르는가?}
        점선 화살표와 역전파 전용 노드들은
        $\mathrm{d}\mathcal{L}$이 어떻게 전파되는지 보여 준다.
        이 화살표를 따라가다 보면,
        어떤 텐서를 역전파를 위해 저장해야 하는지,
        그리고 어디서 활성값을 다시 계산할 수 있는지가 드러난다.
  \item \textbf{메모리는 어디에서 쓰이는가?}
        순전파 텐서가 역전파에서 다시 필요해지는 지점은
        모두 활성값 메모리에 기여한다.
        특히 어텐션 스코어 텐서 $[B,N_H,S,S]$와
        MLP 중간 텐서 $[B,S,D_{\text{ff}}]$는
        메모리 사용량이 크다.
  \item \textbf{집합 통신은 어디에서 발생하는가?}
        TP/DP 다이어그램에서는 색깔이 있는 화살표나
        라벨이 붙은 화살표가 All-Reduce/All-Gather를 나타낸다.
        이 위치들이 많은 디바이스로 확장할 때의
        통신 비용과 크리티컬 패스 길이를 결정한다.
\end{itemize}

이러한 “어휘”에 익숙해지면,
새로운 아키텍처(예: 변형된 MLP, 다른 어텐션 메커니즘)를 보았을 때도
그 핵심적인 연산 비용과 병렬화 패턴을
곧바로 스케치할 수 있게 된다.

\subsection{실용적인 규칙 정리}

다음의 비공식적인 규칙들은
앞선 장들에서의 실용적인 교훈들을 간단히 요약한 것이다.

\begin{itemize}
  \item \textbf{항상 단일 노드 그래프에서 시작하라.}
        추론을 시작할 때는 언제나 가장 단순한 관점에서 출발하라:
        이 모델이 단일 디바이스에서 실행된다면
        무엇을 어떻게 할 것인가?
        그다음 TP와 DP를 그 위에 겹쳐서 생각한다.
  \item \textbf{코드 줄 수가 아니라 matmul 개수로 생각하라.}
        토큰당 등장하는 큰 matmul이 몇 개인지 세고,
        그 각각에 대해 역전파에서
        (대략 두 배) 추가 비용을 지불해야 한다는 사실을 기억하라.
  \item \textbf{TP는 메모리를 줄이는 대신, 레이어 내부 통신을 추가한다.}
        피처 차원 방향으로 샤딩하면
        디바이스당 메모리는 줄어들지만,
        레이어 내부에 All-Reduce/All-Gather가 생긴다.
        모델이 단일 디바이스 메모리에 들어가지 않을 때
        사용하는 수단이다.
  \item \textbf{DP는 전역 배치 크기를 늘리는 대신, 기울기 통신을 추가한다.}
        모델을 복제하는 방식은 단순하고
        레이어 그래프를 그대로 유지하지만,
        모든 파라미터가 기울기 All-Reduce에 참여해야 한다.
  \item \textbf{아주 큰 모델에서는 보통 DP + TP가 기본값이다.}
        실제 대규모 시스템에서는 TP로 모델을 “맞추고”,
        DP로 배치와 처리량을 확장하는 조합이 일반적이다.
  \item \textbf{스케일링 한계는 집합 통신이 정한다.}
        모델이 메모리에 들어간 이후에는,
        추가적인 속도 향상은 거의
        All-Reduce/All-Gather의 개수, 크기, 위치에 의해 제한된다.
\end{itemize}

\subsection{다음 단계}

이 문서는 의도적으로 하나의 트랜스포머 레이어와
소수의 병렬화 전략에 집중했다.
실제 시스템에서의 확장은 다음과 같은 기법들을 포함한다.

\begin{itemize}
  \item \textbf{파이프라인 병렬화(pipeline parallelism):}
        레이어들을 깊이 방향으로 디바이스에 나누고,
        마이크로 배치를 중첩(overlap)시키는 방식.
  \item \textbf{활성값 체크포인팅(activation checkpointing):}
        활성값 메모리를 줄이는 대신,
        역전파 시 일부 순전파를 재계산하는 방식.
  \item \textbf{옵티마이저/파라미터 샤딩:}
        옵티마이저 상태와 심지어 파라미터 자체를
        노드들에 더 복잡한 방식으로 분산(shard)하는 기법들.
\end{itemize}

그러나 핵심 사고 모형은 그대로다.
먼저 단일 노드 다이어그램처럼
정확한 계산 그래프를 세운 뒤,
다음 세 가지 질문을 던진다:
이 그래프가 디바이스들 사이에 어떻게 잘리는가,
통신은 어디에 나타나는가,
그리고 기울기는 어떻게 집계되는가.
이 세 가지가 명확하다면,
겉보기에는 복잡해 보이는 대부분의 병렬 구성도
익숙한 기본 블록들로 환원해 이해할 수 있다.
